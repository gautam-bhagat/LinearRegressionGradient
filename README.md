# Linear Regression using Gradient Descent

## Linear Regression
<p>Linear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting. Different regression models differ based on â€“ the kind of relationship between dependent and independent variables they are considering, and the number of independent variables getting used.</p>

<p>Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x). So, this regression technique finds out a linear relationship between x (input) and y(output). Hence, the name is Linear Regression.
In the figure above, X (input) is the work experience and Y (output) is the salary of a person. The regression line is the best fit line for our model.</p>

<br><br>
### Hypothesis function for Linear Regression :
<h2> <blockquote ><i>h<sub>&theta;</sub> (x) = &theta;<sub>0</sub> + &theta;<sub>1</sub>x</i></blockquote></h2>

<br><br>
## What is Gradient Descent?
<p>Gradient descent (GD) is an iterative first-order optimisation algorithm used to find a local minimum/maximum of a given function. This method is commonly used in machine learning (ML) and deep learning(DL) to minimise a cost/loss function (e.g. in a linear regression).</p>
